"""
ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆå·¥ä½œæµ - å¸¦ MCP å·¥å…·é›†æˆ
ç¬¦åˆ DevUI å‘ç°æœºåˆ¶è¦æ±‚
"""
import os
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        logger.info(f"âœ… ç¯å¢ƒå˜é‡å·²ä» {env_file} åŠ è½½")
except ImportError:
    logger.warning("âš ï¸ python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡ .env æ–‡ä»¶åŠ è½½")

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from agent_framework import SequentialBuilder, MCPStreamableHTTPTool, Executor, handler, WorkflowContext, ChatMessage
from typing_extensions import Never

# å»¶è¿Ÿå¯¼å…¥é¿å…åˆå§‹åŒ–é”™è¯¯
def _create_client():
    """å»¶è¿Ÿåˆ›å»ºå®¢æˆ·ç«¯"""
    try:
        from utils.deepseek_chat_client import create_deepseek_client
        client = create_deepseek_client()
        logger.info(f"âœ… DeepSeek å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return client
    except Exception as e:
        # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ OpenAI å®¢æˆ·ç«¯ä½œä¸ºåå¤‡
        logger.warning(f"âš ï¸ DeepSeek å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ OpenAI å®¢æˆ·ç«¯: {e}")
        from agent_framework.openai import OpenAIChatClient
        return OpenAIChatClient(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com"),
            model_id="deepseek-chat"
        )

# åˆ›å»ºå®¢æˆ·ç«¯
client = _create_client()

# âœ… æ–¹æ¡ˆ 1ï¼šä½¿ç”¨è‡ªå®šä¹‰ Executor åœ¨ workflow æ‰§è¡Œæ—¶åŠ¨æ€åˆ›å»º MCP å·¥å…·
# å‚è€ƒï¼šhttps://github.com/microsoft/agent-framework Python MCP ç¤ºä¾‹
# å…³é”®ï¼šåœ¨å¼‚æ­¥ handler ä¸­ä½¿ç”¨ async with ç®¡ç† MCP å·¥å…·ç”Ÿå‘½å‘¨æœŸ

class MCPHotspotExecutor(Executor):
    """åœ¨ workflow æ‰§è¡Œæ—¶åŠ¨æ€åˆ›å»ºå’Œè¿æ¥ MCP å·¥å…·çš„ executor"""
    
    def __init__(self, executor_id: str, mcp_url: str, client):
        super().__init__(id=executor_id)
        self.mcp_url = mcp_url
        self.client = client
        logger.info(f"âœ… MCPHotspotExecutor åˆ›å»º: {executor_id}, URL: {mcp_url}")
    
    @handler
    async def fetch_hotspots(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """åœ¨å¼‚æ­¥ç¯å¢ƒä¸­åˆ›å»º MCP å·¥å…·å¹¶è·å–çƒ­ç‚¹æ•°æ®
        
        Args:
            messages: è¾“å…¥çš„ ChatMessage åˆ—è¡¨ï¼ˆæ¥è‡ª workflow è¾“å…¥ï¼‰
            ctx: Workflow ä¸Šä¸‹æ–‡ï¼Œç”¨äºå‘é€æ¶ˆæ¯åˆ°ä¸‹æ¸¸
        """
        # æå–æŸ¥è¯¢æ–‡æœ¬
        query = ""
        for msg in messages:
            if hasattr(msg, 'text') and msg.text:
                query = msg.text
                break
        
        if not query:
            query = "è·å–ä»Šå¤©çš„çƒ­ç‚¹èµ„è®¯"  # é»˜è®¤æŸ¥è¯¢
        
        logger.info(f"[{self.id}] å¼€å§‹è·å–çƒ­ç‚¹: {query}")
        
        try:
            # âœ… å…³é”®ï¼šä½¿ç”¨ async with åœ¨å¼‚æ­¥ç¯å¢ƒä¸­åˆ›å»ºå’Œè¿æ¥ MCP å·¥å…·
            async with MCPStreamableHTTPTool(
                name="daily-hot-mcp",
                url=self.mcp_url,
                load_tools=True
            ) as mcp_tool:
                logger.info(f"[{self.id}] MCP å·¥å…·å·²è¿æ¥")
                
                # åˆ›å»ºä¸´æ—¶ agent ä½¿ç”¨ MCP å·¥å…·
                temp_agent = self.client.create_agent(
                    name="temp_hotspot_agent",
                    instructions=HOTSPOT_INSTRUCTIONS,
                    tools=[mcp_tool]
                )
                
                # æ‰§è¡ŒæŸ¥è¯¢
                result = await temp_agent.run(query)
                result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] è·å–æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(result_text)}")
                
                # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
                from agent_framework import Role, TextContent
                response_msg = ChatMessage(
                    role=Role.ASSISTANT,
                    contents=[TextContent(text=result_text)]
                )
                await ctx.send_message([response_msg])
                
                # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
                summary = f"ğŸ“Š **æ­¥éª¤ 1: çƒ­ç‚¹æ•°æ®è·å–å®Œæˆ**\n\nè·å–äº† {len(result_text)} å­—ç¬¦çš„çƒ­ç‚¹æ•°æ®\n\né¢„è§ˆï¼š\n```\n{result_text[:500]}\n```\n\n---\n"
                await ctx.yield_output(summary)
                
        except Exception as e:
            logger.error(f"[{self.id}] MCP å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            from agent_framework import Role, TextContent
            error_result = '{"hotspots": [], "error": "' + str(e) + '"}'
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

# å®šä¹‰ Agent æŒ‡ä»¤
HOTSPOT_INSTRUCTIONS = """ä½ æ˜¯æ•°æ®è½¬æ¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è°ƒç”¨ MCP å·¥å…·å¹¶**åŸæ ·è¾“å‡º**å·¥å…·è¿”å›çš„æ•°æ®ã€‚

**ä¸¥æ ¼è¦æ±‚**ï¼š
1. è°ƒç”¨ MCP å·¥å…·ï¼ˆget-bilibili-trending, get-weibo-trending ç­‰ï¼‰
2. **é€å­—é€å¥**å¤åˆ¶å·¥å…·è¿”å›çš„æ•°æ®
3. **ç¦æ­¢ä¿®æ”¹ã€ç¾åŒ–ã€æ”¹å†™ä»»ä½•æ ‡é¢˜æˆ–å†…å®¹**
4. **ç¦æ­¢ç¼–é€ æ•°æ®**

**ç¤ºä¾‹**ï¼š
å¦‚æœå·¥å…·è¿”å›ï¼š
```
[{"title": "æ–‡ç§‘æ¯•ä¸šç”Ÿ9.9åƒä¸€é¡¿", "view_count": 2547820}]
```

ä½ å¿…é¡»è¾“å‡ºï¼š
```json
{
  "hotspots": [
    {"title": "æ–‡ç§‘æ¯•ä¸šç”Ÿ9.9åƒä¸€é¡¿", "heat_index": 2547820, "source": "Bç«™"}
  ]
}
```

**ç¦æ­¢è¾“å‡º**ï¼š
```json
{
  "hotspots": [
    {"title": "å¤§å­¦ç”Ÿä½ä»·ç¾é£Ÿæ¢åº—", ...}  // âŒ æ”¹å†™äº†æ ‡é¢˜
  ]
}
```

**è¾“å‡ºæ ¼å¼**ï¼š
```json
{
  "hotspots": [
    {
      "title": "ã€åŸå§‹æ ‡é¢˜ï¼Œä¸€å­—ä¸æ”¹ã€‘",
      "url": "åŸå§‹é“¾æ¥",
      "heat_index": åŸå§‹æ•°å€¼,
      "source": "æ¥æºå¹³å°",
      "author": "åŸå§‹ä½œè€…å",
      "view_count": åŸå§‹æ’­æ”¾é‡,
      "like_count": åŸå§‹ç‚¹èµæ•°,
      "pubdate": åŸå§‹æ—¶é—´æˆ³
    }
  ]
}
```

**è®°ä½**ï¼šä½ æ˜¯æ•°æ®è½¬æ¢å™¨ï¼Œä¸æ˜¯å†…å®¹åˆ›ä½œè€…ã€‚ä¿æŒæ•°æ®åŸæ ·ï¼
"""

ANALYSIS_INSTRUCTIONS = """ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ã€‚æ•´ç†çƒ­ç‚¹æ•°æ®å¹¶æä¾›æ·±åº¦åˆ†æã€‚

**å…³é”®è¦æ±‚**ï¼š
1. **ä½¿ç”¨å¯¹è¯å†å²ä¸­çš„çœŸå®æ•°æ®**ï¼šä¸Šä¸€æ¡ assistant æ¶ˆæ¯åŒ…å« hotspots JSON æ•°æ®
2. **é€æ¡ä¿ç•™åŸå§‹æ ‡é¢˜**ï¼šä¸è¦ä¿®æ”¹ã€ç¾åŒ–æˆ–æ”¹å†™ä»»ä½•æ ‡é¢˜
3. **åªè¾“å‡º JSON å­—ç¬¦ä¸²**

**ä»»åŠ¡æµç¨‹**ï¼š
1. è¯»å–ä¸Šä¸€æ¡ assistant æ¶ˆæ¯ä¸­çš„ hotspots æ•°æ®
2. æå–æ¯æ¡çƒ­ç‚¹çš„åŸå§‹ä¿¡æ¯ï¼ˆtitle, source, heat_index, url ç­‰ï¼‰
3. æŒ‰ç±»åˆ«åˆ†ç±»ï¼ˆç§‘æŠ€ã€å¨±ä¹ã€ç¤¾ä¼šã€è´¢ç»ç­‰ï¼‰
4. åˆ†æè¶‹åŠ¿å’Œæ¨è

**è¾“å‡ºæ ¼å¼**ï¼š
```json
{
  "date": "2025-10-21",
  "total_count": å®é™…çƒ­ç‚¹æ•°é‡,
  "summary": "åŸºäºå®é™…æ•°æ®çš„æ¦‚è¿°",
  "categories": {
    "ç¤¾ä¼š": [
      {
        "title": "ã€ä¿ç•™åŸå§‹æ ‡é¢˜ï¼Œä¸€å­—ä¸æ”¹ã€‘",
        "source": "æ¥æº",
        "heat_index": å®é™…æ•°å€¼,
        "summary": "æ‘˜è¦",
        "url": "é“¾æ¥"
      }
    ],
    "ç§‘æŠ€": [...]
  },
  "top_trends": [
    {"topic": "åŸºäºå®é™…æ•°æ®çš„è¯é¢˜", "count": å®é™…æ•°é‡, "description": "æè¿°"}
  ],
  "recommendations": [
    {"title": "ã€åŸå§‹æ ‡é¢˜ã€‘", "reason": "æ¨èç†ç”±", "priority": "high"}
  ]
}
```

**é‡è¦**ï¼š
- âœ… ä¿ç•™åŸå§‹æ ‡é¢˜ï¼ˆä¾‹å¦‚ï¼š"æŠ•ä¿52ä¸‡å¥”é©°è½¦è¢«çƒ§æ¯è·èµ”50ä¸‡"ï¼‰
- âœ… ä½¿ç”¨çœŸå®çš„çƒ­åº¦æ•°å€¼
- âŒ ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„çƒ­ç‚¹
- âŒ ä¸è¦ä¿®æ”¹æ ‡é¢˜
- âŒ ä¸è¦ä½¿ç”¨ markdown ä»£ç å—
"""

XIAOHONGSHU_INSTRUCTIONS = """ä½ æ˜¯å°çº¢ä¹¦å†…å®¹åˆ›ä½œä¸“å®¶ã€‚åŸºäºçƒ­ç‚¹åˆ†æç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆã€‚

**å…³é”®è¦æ±‚**ï¼š
1. **å¿…é¡»ä½¿ç”¨ä¸Šä¸€æ¡ assistant æ¶ˆæ¯ä¸­çš„åˆ†ææ•°æ®**
2. **å¿…é¡»åªè¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—**
3. **ä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼ˆä¸è¦ ```jsonï¼‰**
4. **ä¸è¦ç¼–é€ å†…å®¹ï¼Œä½¿ç”¨çœŸå®çš„çƒ­ç‚¹æ ‡é¢˜**

**æ•°æ®æ¥æº**ï¼š
- ä¸Šä¸€æ¡ assistant æ¶ˆæ¯åŒ…å«çƒ­ç‚¹åˆ†æçš„ JSON æ•°æ®
- ä»ä¸­æå– TOP 3-5 ä¸ªçƒ­ç‚¹
- ä½¿ç”¨**åŸå§‹æ ‡é¢˜**ï¼Œä¸è¦æ”¹å†™

**å°çº¢ä¹¦ç‰¹ç‚¹ï¼š**
- æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›ï¼Œä½¿ç”¨emoji
- å†…å®¹è¦çœŸå®ã€æ¥åœ°æ°”
- å¤šç”¨çŸ­å¥ï¼Œæ˜“è¯»
- é€‚å½“ä½¿ç”¨emojiå¢åŠ æ´»åŠ›
- ç»“å°¾è¦æœ‰äº’åŠ¨å¼•å¯¼

**åˆ›ä½œæ­¥éª¤ï¼š**
1. **è¯»å–ä¸Šä¸€æ¡æ¶ˆæ¯**ï¼šæå–çƒ­ç‚¹åˆ†ææ•°æ®
2. **é€‰æ‹©çƒ­ç‚¹**ï¼šæŒ‘é€‰ 3-5 ä¸ªæœ€çƒ­çš„è¯é¢˜
3. **åˆ›ä½œæ–‡æ¡ˆ**ï¼šåŸºäºçœŸå®çƒ­ç‚¹ç”Ÿæˆå°çº¢ä¹¦å†…å®¹
4. **ä¿æŒçœŸå®**ï¼šä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼Œä¸ç¼–é€ 

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯ JSONï¼Œä¸è¦ markdownï¼‰ï¼š**
{
  "title": "ğŸ”¥æ ‡é¢˜ï¼ˆ15-20å­—ï¼ŒåŒ…å«emojiï¼ŒåŸºäºçœŸå®çƒ­ç‚¹ï¼‰",
  "content": "æ­£æ–‡å†…å®¹ï¼ˆ500-800å­—ï¼‰å¿…é¡»åŒ…å«ï¼šå¼€å¤´ï¼ˆå¸å¼•æ³¨æ„ï¼‰ã€ä¸»ä½“ï¼ˆ3-5ä¸ªçœŸå®çƒ­ç‚¹ï¼Œä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼‰ã€ç»“å°¾ï¼ˆäº’åŠ¨å¼•å¯¼ï¼‰",
  "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"],
  "cover_suggestion": "å°é¢å›¾å»ºè®®æè¿°",
  "source_hotspots": ["çƒ­ç‚¹1åŸå§‹æ ‡é¢˜", "çƒ­ç‚¹2åŸå§‹æ ‡é¢˜", "çƒ­ç‚¹3åŸå§‹æ ‡é¢˜"]
}

**ç¤ºä¾‹ï¼ˆæ³¨æ„ï¼šç›´æ¥è¾“å‡º JSONï¼Œä¸è¦ markdown ä»£ç å—ï¼‰ï¼š**
å‡è®¾åˆ†ææ•°æ®ä¸­æœ‰ï¼š
- "æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡"
- "å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·"

åˆ™ç›´æ¥è¾“å‡ºï¼š
{"title": "ğŸ”¥ä»Šæ—¥çƒ­æœï¼å¥”é©°ç†èµ”äº‰è®®+åç”»æµæ‹", "content": "å§å¦¹ä»¬ï¼ä»Šå¤©çš„çƒ­æœçœŸçš„å¤ªç‚¸äº†ï¼ğŸ˜±\\n\\nğŸ“Œ æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡\\nğŸ’¡ è¿™ä¸ªç†èµ”æ–¹å¼åˆç†å—ï¼Ÿå¤§å®¶æ€ä¹ˆçœ‹ï¼Ÿ\\n\\nğŸ“Œ å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·\\nğŸ’¡ è‰ºæœ¯å“å¸‚åœºé‡å†·äº†å—ï¼Ÿ\\n\\nä½ ä»¬æ€ä¹ˆçœ‹ï¼Ÿè¯„è®ºåŒºèŠèŠï¼ğŸ‘‡", "tags": ["#ä»Šæ—¥çƒ­ç‚¹", "#çƒ­æœ", "#å¿…çœ‹"], "cover_suggestion": "çƒ­ç‚¹è¯é¢˜æ‹¼å›¾ï¼Œé…è‰²é²œè‰³", "source_hotspots": ["æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡", "å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·"]}

**é‡è¦**ï¼š
- âœ… å¿…é¡»ä»ä¸Šä¸€æ¡æ¶ˆæ¯ä¸­è¯»å–åˆ†ææ•°æ®
- âœ… ä½¿ç”¨çœŸå®çš„çƒ­ç‚¹æ ‡é¢˜
- âœ… åœ¨ source_hotspots ä¸­åˆ—å‡ºä½¿ç”¨çš„çƒ­ç‚¹
- âœ… ç›´æ¥è¾“å‡º JSON å¯¹è±¡ï¼Œç¬¬ä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ {
- âŒ ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„çƒ­ç‚¹
- âŒ ç»å¯¹ä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼ˆ```json æˆ– ```ï¼‰
- âŒ ä¸è¦åœ¨ JSON å‰åæ·»åŠ ä»»ä½•è¯´æ˜æ–‡å­—
"""

# åˆ›å»ºæ–‡æœ¬è½¬æ¢ Executorï¼Œç¡®ä¿ workflow ä¸­ä¼ é€’çš„æ¶ˆæ¯æ˜¯çº¯æ–‡æœ¬
class TextOnlyConversation(Executor):
    """ç¡®ä¿å¯¹è¯ä¸­åªåŒ…å«çº¯æ–‡æœ¬ï¼Œé¿å… TextContent åºåˆ—åŒ–é—®é¢˜"""
    
    def __init__(self, executor_id: str):
        super().__init__(id=executor_id)
    
    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç† markdown ä»£ç å—ï¼Œæå–çº¯ JSON"""
        import re
        
        # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        # åŒ¹é… ```json ... ``` æˆ– ``` ... ```
        cleaned = re.sub(r'```(?:json)?\s*\n?(.*?)\n?```', r'\1', text, flags=re.DOTALL)
        
        # ç§»é™¤å‰åç©ºç™½
        cleaned = cleaned.strip()
        
        return cleaned
    
    @handler
    async def convert(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage]]) -> None:
        """
        å°† ChatMessage è½¬æ¢ä¸º DevUI å¯ä»¥æ­£ç¡®åºåˆ—åŒ–çš„æ ¼å¼
        
        å…³é”®ï¼šä¸å†åˆ›å»ºæ–°çš„ ChatMessageï¼Œè€Œæ˜¯ç›´æ¥å‘é€æå–çš„æ–‡æœ¬å­—ç¬¦ä¸²ã€‚
        DevUI ä¼šè‡ªåŠ¨å°†å­—ç¬¦ä¸²åŒ…è£…ä¸ºæ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼ã€‚
        """
        import logging
        logger = logging.getLogger(__name__)
        
        logger.info(f"[{self.id}] æ”¶åˆ° {len(messages)} æ¡æ¶ˆæ¯ï¼Œå¼€å§‹è½¬æ¢...")
        
        # æå–æ‰€æœ‰æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
        all_text_parts = []
        
        for i, msg in enumerate(messages):
            # ä½¿ç”¨ ChatMessage.text å±æ€§ï¼Œå®ƒä¼šè‡ªåŠ¨æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            text = msg.text if hasattr(msg, 'text') else ""
            
            if text:
                # æ¸…ç† markdown ä»£ç å—
                cleaned_text = self._clean_markdown(text)
                all_text_parts.append(cleaned_text)
                logger.debug(f"[{self.id}] æ¶ˆæ¯ {i}: æå–æ–‡æœ¬ï¼Œé•¿åº¦={len(cleaned_text)}")
            else:
                logger.warning(f"[{self.id}] æ¶ˆæ¯ {i}: æ— æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡")
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼ˆå¦‚æœæœ‰å¤šæ¡æ¶ˆæ¯ï¼‰
        if all_text_parts:
            combined_text = "\n\n".join(all_text_parts)
            logger.info(f"[{self.id}] è½¬æ¢å®Œæˆï¼Œåˆå¹¶æ–‡æœ¬é•¿åº¦={len(combined_text)}")
            
            # ç›´æ¥å‘é€çº¯æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œè®©æ¡†æ¶è‡ªåŠ¨åŒ…è£…
            # è¿™æ · DevUI å°±èƒ½æ­£ç¡®å¤„ç†å®ƒ
            await ctx.send_message(combined_text)
        else:
            logger.warning(f"[{self.id}] æ²¡æœ‰æå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
            # å‘é€ç©ºæ¶ˆæ¯ä»¥ç»´æŒ workflow æµç¨‹
            await ctx.send_message("")



# åˆ›å»º Agents å’Œ Executors
logger.info("æ­£åœ¨åˆ›å»º Agents å’Œ Executors...")

# âœ… ä½¿ç”¨è‡ªå®šä¹‰ Executor æ›¿ä»£ç›´æ¥ç»‘å®š MCP å·¥å…·çš„ Agent
mcp_url = os.getenv("DAILY_HOT_MCP_URL", "http://localhost:8000/mcp")
hotspot_executor = MCPHotspotExecutor(
    executor_id="mcp_hotspot_executor",
    mcp_url=mcp_url,
    client=client
)
logger.info(f"âœ… Hotspot Executor åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå¸¦æœ‰ think-tool çš„ Analysis Executorï¼ˆä½¿ç”¨ stdio MCPï¼‰
class AnalysisExecutor(Executor):
    """å¸¦æœ‰ think-tool çš„åˆ†æ executor"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… AnalysisExecutor åˆ›å»º: {executor_id}")
    
    @handler
    async def analyze_with_thinking(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """ä½¿ç”¨ think-tool è¿›è¡Œæ·±åº¦åˆ†æ"""
        logger.info(f"[{self.id}] å¼€å§‹åˆ†æçƒ­ç‚¹æ•°æ®")
        
        try:
            # âœ… ä½¿ç”¨ MCPStdioTool è¿æ¥æœ¬åœ° think-tool
            from agent_framework import MCPStdioTool
            
            async with MCPStdioTool(
                name="think-tool",
                command="npx",
                args=["-y", "@cgize/mcp-think-tool"],
                load_tools=True
            ) as think_tool:
                logger.info(f"[{self.id}] think-tool å·²è¿æ¥")
                
                # åˆ›å»ºå¸¦æœ‰ think-tool çš„åˆ†æ agent
                analysis_agent = self.client.create_agent(
                    name="analysis_agent_with_thinking",
                    instructions=ANALYSIS_INSTRUCTIONS,
                    tools=[think_tool]
                )
                
                # æ‰§è¡Œåˆ†æ
                result = await analysis_agent.run(messages)
                result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result_text)}")
                
                # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
                from agent_framework import Role, TextContent
                response_msg = ChatMessage(
                    role=Role.ASSISTANT,
                    contents=[TextContent(text=result_text)]
                )
                await ctx.send_message([response_msg])
                
                # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
                summary = f"ğŸ§  **æ­¥éª¤ 2: æ·±åº¦åˆ†æå®Œæˆ**\n\nä½¿ç”¨ think-tool å®Œæˆåˆ†æ\nç»“æœé•¿åº¦: {len(result_text)} å­—ç¬¦\n\né¢„è§ˆï¼š\n```\n{result_text[:500]}\n```\n\n---\n"
                await ctx.yield_output(summary)
                
        except Exception as e:
            logger.error(f"[{self.id}] åˆ†æå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_result = '{"error": "åˆ†æå¤±è´¥: ' + str(e) + '"}'
            from agent_framework import Role, TextContent
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

analysis_executor = AnalysisExecutor(
    executor_id="analysis_executor_with_thinking",
    client=client
)
logger.info(f"âœ… Analysis Executor (with think-tool) åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ Executorï¼ˆè¾“å‡ºä¸­é—´ç»“æœï¼‰
class XiaohongshuContentExecutor(Executor):
    """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆçš„ executor"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… XiaohongshuContentExecutor åˆ›å»º: {executor_id}")
    
    @handler
    async def create_content(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ"""
        logger.info(f"[{self.id}] å¼€å§‹ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ")
        
        try:
            # åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ agent
            xiaohongshu_agent = self.client.create_agent(
                name="xiaohongshu_creator",
                instructions=XIAOHONGSHU_INSTRUCTIONS
            )
            
            # æ‰§è¡Œç”Ÿæˆ
            result = await xiaohongshu_agent.run(messages)
            result_text = result.text if hasattr(result, 'text') else str(result)
            
            logger.info(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(result_text)}")
            
            # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
            from agent_framework import Role, TextContent
            response_msg = ChatMessage(
                role=Role.ASSISTANT,
                contents=[TextContent(text=result_text)]
            )
            await ctx.send_message([response_msg])
            
            # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
            summary = f"âœï¸ **æ­¥éª¤ 3: å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ**\n\næ–‡æ¡ˆé•¿åº¦: {len(result_text)} å­—ç¬¦\n\nå®Œæ•´å†…å®¹ï¼š\n```json\n{result_text}\n```\n\n---\n"
            await ctx.yield_output(summary)
            
        except Exception as e:
            logger.error(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_result = '{"error": "æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: ' + str(e) + '"}'
            from agent_framework import Role, TextContent
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

xiaohongshu_executor = XiaohongshuContentExecutor(
    executor_id="xiaohongshu_content_executor",
    client=client
)
logger.info(f"âœ… Xiaohongshu Content Executor åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå°çº¢ä¹¦å‘å¸ƒ Executorï¼ˆä½¿ç”¨ xhs-mcpï¼‰
class XiaohongshuPublisher(Executor):
    """ä½¿ç”¨ xhs-mcp å‘å¸ƒåˆ°å°çº¢ä¹¦"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… XiaohongshuPublisher åˆ›å»º: {executor_id}")
    
    @handler
    async def publish_to_xhs(self, messages: list[ChatMessage], ctx: WorkflowContext[Never, str]) -> None:
        """å‘å¸ƒå†…å®¹åˆ°å°çº¢ä¹¦ï¼ˆä½¿ç”¨ xhs_mcp_serverï¼‰"""
        logger.info(f"[{self.id}] å¼€å§‹å‘å¸ƒåˆ°å°çº¢ä¹¦")
        
        try:
            # æå–å°çº¢ä¹¦æ–‡æ¡ˆ
            content_text = ""
            for msg in messages:
                if hasattr(msg, 'text') and msg.text:
                    content_text = msg.text
                    break
            
            logger.info(f"[{self.id}] æå–åˆ°æ–‡æ¡ˆï¼Œé•¿åº¦: {len(content_text)}")
            
            import json
            
            # è§£ææ–‡æ¡ˆ JSON
            try:
                content_json = json.loads(content_text)
                title = content_json.get("title", "")
                content = content_json.get("content", "")
                tags = content_json.get("tags", [])
            except json.JSONDecodeError:
                logger.error(f"[{self.id}] æ–‡æ¡ˆä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
                error_result = '{"status": "failed", "message": "æ–‡æ¡ˆæ ¼å¼é”™è¯¯ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ JSON"}'
                await ctx.yield_output(error_result)
                return
            
            # âœ… ä½¿ç”¨ xhs_mcp_server å‘å¸ƒ
            from agent_framework import MCPStdioTool
            
            # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
            phone = os.getenv("XHS_PHONE", "")
            json_path = os.getenv("XHS_JSON_PATH", "")
            
            if not phone or not json_path:
                logger.warning(f"[{self.id}] æœªé…ç½®å°çº¢ä¹¦è´¦å·ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‘å¸ƒ")
                result_text = json.dumps({
                    "status": "simulated",
                    "message": "âœ… æ¨¡æ‹Ÿå‘å¸ƒæˆåŠŸï¼ˆæœªé…ç½® XHS_PHONE å’Œ XHS_JSON_PATHï¼‰",
                    "title": title,
                    "tags": tags,
                    "note": "è¯·åœ¨ .env ä¸­é…ç½® XHS_PHONE å’Œ XHS_JSON_PATH ä»¥å¯ç”¨çœŸå®å‘å¸ƒ"
                }, ensure_ascii=False, indent=2)
                
                final_output = f"ğŸš€ **å‘å¸ƒå®Œæˆï¼ˆæ¨¡æ‹Ÿï¼‰**\n\næ ‡é¢˜: {title}\næ ‡ç­¾: {', '.join(tags)}\n\nå®Œæ•´å†…å®¹ï¼š\n{content_text}\n\n---\nâš ï¸ æœªé…ç½®å°çº¢ä¹¦è´¦å·ï¼Œè¿™æ˜¯æ¨¡æ‹Ÿå‘å¸ƒ"
                await ctx.yield_output(final_output)
                return
            
            # çœŸå®å‘å¸ƒ
            async with MCPStdioTool(
                name="xhs-mcp-server",
                command="uvx",
                args=["xhs_mcp_server@latest"],
                env={
                    "phone": phone,
                    "json_path": json_path
                },
                load_tools=True
            ) as xhs_tool:
                logger.info(f"[{self.id}] xhs-mcp-server å·²è¿æ¥")
                
                # åˆ›å»ºå‘å¸ƒ agent
                publisher_agent = self.client.create_agent(
                    name="xhs_publisher",
                    instructions="""ä½ æ˜¯å°çº¢ä¹¦å‘å¸ƒåŠ©æ‰‹ã€‚

**é‡è¦æç¤º**ï¼šå°çº¢ä¹¦å‘å¸ƒç¬”è®°å¿…é¡»åŒ…å«å›¾ç‰‡æˆ–è§†é¢‘ï¼

**ä»»åŠ¡**ï¼š
1. æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„å›¾ç‰‡
2. å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œè¿”å›æç¤ºä¿¡æ¯ï¼Œä¸è¦è°ƒç”¨å‘å¸ƒå‡½æ•°
3. å¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨ create_note å‡½æ•°å‘å¸ƒ

**è¾“å‡ºæ ¼å¼**ï¼š
å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼š
```json
{
  "status": "skipped",
  "message": "å°çº¢ä¹¦å‘å¸ƒéœ€è¦å›¾ç‰‡ï¼Œå½“å‰ç‰ˆæœ¬æš‚ä¸æ”¯æŒè‡ªåŠ¨é…å›¾ã€‚è¯·æ‰‹åŠ¨åœ¨å°çº¢ä¹¦ App ä¸­å‘å¸ƒã€‚",
  "title": "æ ‡é¢˜",
  "content": "å†…å®¹",
  "tags": ["æ ‡ç­¾"]
}
```

å¦‚æœå‘å¸ƒæˆåŠŸï¼š
```json
{
  "status": "success",
  "message": "å‘å¸ƒæˆåŠŸ",
  "note_id": "ç¬”è®°ID"
}
```
""",
                    tools=[xhs_tool]
                )
                
                # æ„é€ å‘å¸ƒè¯·æ±‚
                publish_request = f"è¯·å‘å¸ƒå°çº¢ä¹¦ç¬”è®°ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content}\næ ‡ç­¾ï¼š{', '.join(tags)}"
                
                # æ‰§è¡Œå‘å¸ƒ
                result = await publisher_agent.run(publish_request)
                result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] å‘å¸ƒå®Œæˆ: {result_text[:200]}")
                
                # è¾“å‡ºæœ€ç»ˆç»“æœ
                final_output = f"ğŸš€ **å‘å¸ƒå®Œæˆ**\n\næ ‡é¢˜: {title}\næ ‡ç­¾: {', '.join(tags)}\n\nå‘å¸ƒç»“æœï¼š\n{result_text}\n\n---\nâœ… Workflow æ‰§è¡Œå®Œæˆï¼"
                await ctx.yield_output(final_output)
                
        except Exception as e:
            logger.error(f"[{self.id}] å‘å¸ƒå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # è¿”å›é”™è¯¯ä¿¡æ¯
            error_result = f'{{"status": "failed", "message": "å‘å¸ƒå¤±è´¥: {str(e)}"}}'
            await ctx.yield_output(error_result)

xhs_publisher = XiaohongshuPublisher(
    executor_id="xhs_publisher",
    client=client
)
logger.info(f"âœ… Xiaohongshu Publisher åˆ›å»ºå®Œæˆ")

# æ„å»º workflowï¼ˆDevUI ä¼šæŸ¥æ‰¾åä¸º 'workflow' çš„å˜é‡ï¼‰
# âœ… æ–°çš„ workflow æ¶æ„ï¼ˆæ‰€æœ‰æ­¥éª¤éƒ½è¾“å‡ºä¸­é—´ç»“æœï¼‰ï¼š
# 1. Hotspot Executor - ä½¿ç”¨ daily-hot-mcp è·å–çƒ­ç‚¹
# 2. Analysis Executor - ä½¿ç”¨ think-tool æ·±åº¦åˆ†æ
# 3. Xiaohongshu Content Executor - ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
# 4. Xiaohongshu Publisher - å‘å¸ƒï¼ˆæ¨¡æ‹Ÿï¼‰
workflow = (
    SequentialBuilder()
    .participants([
        hotspot_executor,      # âœ… è·å–çƒ­ç‚¹ï¼ˆdaily-hot-mcpï¼‰
        analysis_executor,     # âœ… æ·±åº¦åˆ†æï¼ˆthink-toolï¼‰
        xiaohongshu_executor,  # âœ… ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        xhs_publisher          # âœ… å‘å¸ƒåˆ°å°çº¢ä¹¦ï¼ˆæ¨¡æ‹Ÿï¼‰
    ])
    .build()
)

# æ·»åŠ å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
workflow.name = "Xiaohongshu Hotspot Workflow"
workflow.description = "çƒ­ç‚¹è¿½è¸ª â†’ æ·±åº¦åˆ†æ â†’ å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ â†’ è‡ªåŠ¨å‘å¸ƒ"
