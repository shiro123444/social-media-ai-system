"""
ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆå·¥ä½œæµ - å¸¦ MCP å·¥å…·é›†æˆ
ç¬¦åˆ DevUI å‘ç°æœºåˆ¶è¦æ±‚
"""
import os
import logging
from pathlib import Path

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    env_file = Path(__file__).parent / ".env"
    if env_file.exists():
        load_dotenv(env_file)
        logger.info(f"âœ… ç¯å¢ƒå˜é‡å·²ä» {env_file} åŠ è½½")
except ImportError:
    logger.warning("âš ï¸ python-dotenv æœªå®‰è£…ï¼Œè·³è¿‡ .env æ–‡ä»¶åŠ è½½")

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from agent_framework import SequentialBuilder, MCPStreamableHTTPTool, Executor, handler, WorkflowContext, ChatMessage
from typing_extensions import Never

# å»¶è¿Ÿå¯¼å…¥é¿å…åˆå§‹åŒ–é”™è¯¯
def _create_client():
    """å»¶è¿Ÿåˆ›å»ºå®¢æˆ·ç«¯"""
    try:
        from utils.deepseek_chat_client import create_deepseek_client
        client = create_deepseek_client()
        logger.info(f"âœ… DeepSeek å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return client
    except Exception as e:
        # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ OpenAI å®¢æˆ·ç«¯ä½œä¸ºåå¤‡
        logger.warning(f"âš ï¸ DeepSeek å®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨ OpenAI å®¢æˆ·ç«¯: {e}")
        from agent_framework.openai import OpenAIChatClient
        return OpenAIChatClient(
            api_key=os.getenv("DEEPSEEK_API_KEY"),
            base_url=os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com"),
            model_id="deepseek-chat"
        )

# åˆ›å»ºå®¢æˆ·ç«¯
client = _create_client()

# âœ… æ–¹æ¡ˆ 1ï¼šä½¿ç”¨è‡ªå®šä¹‰ Executor åœ¨ workflow æ‰§è¡Œæ—¶åŠ¨æ€åˆ›å»º MCP å·¥å…·
# å‚è€ƒï¼šhttps://github.com/microsoft/agent-framework Python MCP ç¤ºä¾‹
# å…³é”®ï¼šåœ¨å¼‚æ­¥ handler ä¸­ä½¿ç”¨ async with ç®¡ç† MCP å·¥å…·ç”Ÿå‘½å‘¨æœŸ

class MCPHotspotExecutor(Executor):
    """åœ¨ workflow æ‰§è¡Œæ—¶åŠ¨æ€åˆ›å»ºå’Œè¿æ¥ MCP å·¥å…·çš„ executor"""
    
    def __init__(self, executor_id: str, mcp_url: str, client):
        super().__init__(id=executor_id)
        self.mcp_url = mcp_url
        self.client = client
        logger.info(f"âœ… MCPHotspotExecutor åˆ›å»º: {executor_id}, URL: {mcp_url}")
    
    @handler
    async def fetch_hotspots(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """åœ¨å¼‚æ­¥ç¯å¢ƒä¸­åˆ›å»º MCP å·¥å…·å¹¶è·å–çƒ­ç‚¹æ•°æ®
        
        Args:
            messages: è¾“å…¥çš„ ChatMessage åˆ—è¡¨ï¼ˆæ¥è‡ª workflow è¾“å…¥ï¼‰
            ctx: Workflow ä¸Šä¸‹æ–‡ï¼Œç”¨äºå‘é€æ¶ˆæ¯åˆ°ä¸‹æ¸¸
        """
        # æå–æŸ¥è¯¢æ–‡æœ¬
        query = ""
        for msg in messages:
            if hasattr(msg, 'text') and msg.text:
                query = msg.text
                break
        
        if not query:
            query = "è·å–ä»Šå¤©çš„çƒ­ç‚¹èµ„è®¯"  # é»˜è®¤æŸ¥è¯¢
        
        logger.info(f"[{self.id}] å¼€å§‹è·å–çƒ­ç‚¹: {query}")
        
        try:
            # âœ… å…³é”®ï¼šä½¿ç”¨ async with åœ¨å¼‚æ­¥ç¯å¢ƒä¸­åˆ›å»ºå’Œè¿æ¥ MCP å·¥å…·
            async with MCPStreamableHTTPTool(
                name="daily-hot-mcp",
                url=self.mcp_url,
                load_tools=True
            ) as mcp_tool:
                logger.info(f"[{self.id}] MCP å·¥å…·å·²è¿æ¥")
                
                # åˆ›å»ºä¸´æ—¶ agent ä½¿ç”¨ MCP å·¥å…·
                temp_agent = self.client.create_agent(
                    name="temp_hotspot_agent",
                    instructions=HOTSPOT_INSTRUCTIONS,
                    tools=[mcp_tool]
                )
                
                # æ‰§è¡ŒæŸ¥è¯¢
                result = await temp_agent.run(query)
                result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] è·å–æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(result_text)}")
                
                # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
                from agent_framework import Role, TextContent
                response_msg = ChatMessage(
                    role=Role.ASSISTANT,
                    contents=[TextContent(text=result_text)]
                )
                await ctx.send_message([response_msg])
                
                # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
                summary = f"ğŸ“Š **æ­¥éª¤ 1: çƒ­ç‚¹æ•°æ®è·å–å®Œæˆ**\n\nè·å–äº† {len(result_text)} å­—ç¬¦çš„çƒ­ç‚¹æ•°æ®\n\né¢„è§ˆï¼š\n```\n{result_text[:500]}\n```\n\n---\n"
                await ctx.yield_output(summary)
                
        except Exception as e:
            logger.error(f"[{self.id}] MCP å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            from agent_framework import Role, TextContent
            error_result = '{"hotspots": [], "error": "' + str(e) + '"}'
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

# å®šä¹‰ Agent æŒ‡ä»¤
HOTSPOT_INSTRUCTIONS = """ä½ æ˜¯æ•°æ®è½¬æ¢ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è°ƒç”¨ MCP å·¥å…·å¹¶**åŸæ ·è¾“å‡º**å·¥å…·è¿”å›çš„æ•°æ®ã€‚

**ä¸¥æ ¼è¦æ±‚**ï¼š
1. è°ƒç”¨ MCP å·¥å…·ï¼ˆget-bilibili-trending, get-weibo-trending ç­‰ï¼‰
2. **é€å­—é€å¥**å¤åˆ¶å·¥å…·è¿”å›çš„æ•°æ®
3. **ç¦æ­¢ä¿®æ”¹ã€ç¾åŒ–ã€æ”¹å†™ä»»ä½•æ ‡é¢˜æˆ–å†…å®¹**
4. **ç¦æ­¢ç¼–é€ æ•°æ®**

**ç¤ºä¾‹**ï¼š
å¦‚æœå·¥å…·è¿”å›ï¼š
```
[{"title": "æ–‡ç§‘æ¯•ä¸šç”Ÿ9.9åƒä¸€é¡¿", "view_count": 2547820}]
```

ä½ å¿…é¡»è¾“å‡ºï¼š
```json
{
  "hotspots": [
    {"title": "æ–‡ç§‘æ¯•ä¸šç”Ÿ9.9åƒä¸€é¡¿", "heat_index": 2547820, "source": "Bç«™"}
  ]
}
```

**ç¦æ­¢è¾“å‡º**ï¼š
```json
{
  "hotspots": [
    {"title": "å¤§å­¦ç”Ÿä½ä»·ç¾é£Ÿæ¢åº—", ...}  // âŒ æ”¹å†™äº†æ ‡é¢˜
  ]
}
```

**è¾“å‡ºæ ¼å¼**ï¼š
```json
{
  "hotspots": [
    {
      "title": "ã€åŸå§‹æ ‡é¢˜ï¼Œä¸€å­—ä¸æ”¹ã€‘",
      "url": "åŸå§‹é“¾æ¥",
      "heat_index": åŸå§‹æ•°å€¼,
      "source": "æ¥æºå¹³å°",
      "author": "åŸå§‹ä½œè€…å",
      "view_count": åŸå§‹æ’­æ”¾é‡,
      "like_count": åŸå§‹ç‚¹èµæ•°,
      "pubdate": åŸå§‹æ—¶é—´æˆ³
    }
  ]
}
```

**è®°ä½**ï¼šä½ æ˜¯æ•°æ®è½¬æ¢å™¨ï¼Œä¸æ˜¯å†…å®¹åˆ›ä½œè€…ã€‚ä¿æŒæ•°æ®åŸæ ·ï¼
"""

ANALYSIS_INSTRUCTIONS = """ä½ æ˜¯æ•°æ®åˆ†æä¸“å®¶ã€‚æ•´ç†çƒ­ç‚¹æ•°æ®å¹¶æä¾›æ·±åº¦åˆ†æã€‚

**å…³é”®è¦æ±‚**ï¼š
1. **ä½¿ç”¨å¯¹è¯å†å²ä¸­çš„çœŸå®æ•°æ®**ï¼šä¸Šä¸€æ¡ assistant æ¶ˆæ¯åŒ…å« hotspots JSON æ•°æ®
2. **é€æ¡ä¿ç•™åŸå§‹æ ‡é¢˜**ï¼šä¸è¦ä¿®æ”¹ã€ç¾åŒ–æˆ–æ”¹å†™ä»»ä½•æ ‡é¢˜
3. **åªè¾“å‡º JSON å­—ç¬¦ä¸²**

**ä»»åŠ¡æµç¨‹**ï¼š
1. è¯»å–ä¸Šä¸€æ¡ assistant æ¶ˆæ¯ä¸­çš„ hotspots æ•°æ®
2. æå–æ¯æ¡çƒ­ç‚¹çš„åŸå§‹ä¿¡æ¯ï¼ˆtitle, source, heat_index, url ç­‰ï¼‰
3. æŒ‰ç±»åˆ«åˆ†ç±»ï¼ˆç§‘æŠ€ã€å¨±ä¹ã€ç¤¾ä¼šã€è´¢ç»ç­‰ï¼‰
4. åˆ†æè¶‹åŠ¿å’Œæ¨è

**è¾“å‡ºæ ¼å¼**ï¼š
```json
{
  "date": "2025-10-21",
  "total_count": å®é™…çƒ­ç‚¹æ•°é‡,
  "summary": "åŸºäºå®é™…æ•°æ®çš„æ¦‚è¿°",
  "categories": {
    "ç¤¾ä¼š": [
      {
        "title": "ã€ä¿ç•™åŸå§‹æ ‡é¢˜ï¼Œä¸€å­—ä¸æ”¹ã€‘",
        "source": "æ¥æº",
        "heat_index": å®é™…æ•°å€¼,
        "summary": "æ‘˜è¦",
        "url": "é“¾æ¥"
      }
    ],
    "ç§‘æŠ€": [...]
  },
  "top_trends": [
    {"topic": "åŸºäºå®é™…æ•°æ®çš„è¯é¢˜", "count": å®é™…æ•°é‡, "description": "æè¿°"}
  ],
  "recommendations": [
    {"title": "ã€åŸå§‹æ ‡é¢˜ã€‘", "reason": "æ¨èç†ç”±", "priority": "high"}
  ]
}
```

**é‡è¦**ï¼š
- âœ… ä¿ç•™åŸå§‹æ ‡é¢˜ï¼ˆä¾‹å¦‚ï¼š"æŠ•ä¿52ä¸‡å¥”é©°è½¦è¢«çƒ§æ¯è·èµ”50ä¸‡"ï¼‰
- âœ… ä½¿ç”¨çœŸå®çš„çƒ­åº¦æ•°å€¼
- âŒ ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„çƒ­ç‚¹
- âŒ ä¸è¦ä¿®æ”¹æ ‡é¢˜
- âŒ ä¸è¦ä½¿ç”¨ markdown ä»£ç å—
"""

XIAOHONGSHU_INSTRUCTIONS = """ä½ æ˜¯å°çº¢ä¹¦å†…å®¹åˆ›ä½œä¸“å®¶ã€‚åŸºäºçƒ­ç‚¹åˆ†æç”Ÿæˆå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆã€‚

**å…³é”®è¦æ±‚**ï¼š
1. **å¿…é¡»ä½¿ç”¨ä¸Šä¸€æ¡ assistant æ¶ˆæ¯ä¸­çš„åˆ†ææ•°æ®**
2. **å¿…é¡»åªè¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—**
3. **ä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼ˆä¸è¦ ```jsonï¼‰**
4. **ä¸è¦ç¼–é€ å†…å®¹ï¼Œä½¿ç”¨çœŸå®çš„çƒ­ç‚¹æ ‡é¢˜**
5. **å¿…é¡»åŒ…å«å…·ä½“ç»†èŠ‚**ï¼šæ—¶é—´ã€æ—¥æœŸã€æ•°æ®ã€äººç‰©ã€åœ°ç‚¹ç­‰

**æ•°æ®æ¥æº**ï¼š
- ä¸Šä¸€æ¡ assistant æ¶ˆæ¯åŒ…å«çƒ­ç‚¹åˆ†æçš„ JSON æ•°æ®
- ä»ä¸­æå– TOP 3-5 ä¸ªçƒ­ç‚¹
- ä½¿ç”¨**åŸå§‹æ ‡é¢˜**ï¼Œä¸è¦æ”¹å†™
- æå–æ‰€æœ‰å¯ç”¨çš„ç»†èŠ‚ä¿¡æ¯ï¼ˆæ—¶é—´ã€æ•°æ®ã€æ¥æºç­‰ï¼‰

**å°çº¢ä¹¦ç‰¹ç‚¹ï¼š**
- æ ‡é¢˜è¦æœ‰å¸å¼•åŠ›ï¼Œä½¿ç”¨emoji
- å†…å®¹è¦çœŸå®ã€æ¥åœ°æ°”ã€æœ‰ç»†èŠ‚
- å¤šç”¨çŸ­å¥ï¼Œæ˜“è¯»
- é€‚å½“ä½¿ç”¨emojiå¢åŠ æ´»åŠ›
- ç»“å°¾è¦æœ‰äº’åŠ¨å¼•å¯¼

**å†…å®¹ç»“æ„ï¼ˆé‡è¦ï¼‰ï¼š**
æ¯æ¡æ–°é—»å¿…é¡»åˆ†æˆä¸¤éƒ¨åˆ†ï¼š
1. **æ–°é—»å†…å®¹**ï¼ˆğŸ“°ï¼‰ï¼šè¯¦ç»†è®²è¿°æ–°é—»ï¼Œå¿…é¡»åŒ…å«ï¼š
   - å…·ä½“æ—¶é—´ï¼ˆå¦‚ï¼š10æœˆ23æ—¥ã€ä»Šå¤©ä¸Šåˆã€æ˜¨å¤©ç­‰ï¼‰
   - å…³é”®æ•°æ®ï¼ˆå¦‚ï¼š52ä¸‡ã€4762ä¸‡ã€783ä¸‡çƒ­åº¦ç­‰ï¼‰
   - å…·ä½“äººç‰©/æœºæ„ï¼ˆå¦‚ï¼šè½¦ä¸»ã€ä¿é™©å…¬å¸ã€æ‹å–è¡Œç­‰ï¼‰
   - äº‹ä»¶ç»è¿‡å’Œç»“æœ
   - æ¥æºå¹³å°ï¼ˆå¦‚ï¼šå¾®åšçƒ­æœã€Bç«™ã€çŸ¥ä¹ç­‰ï¼‰

2. **æ—¶è¯„/è§‚ç‚¹**ï¼ˆğŸ’­ï¼‰ï¼šå‘è¡¨çœ‹æ³•ï¼Œå¯ä»¥åŒ…å«ï¼š
   - å¯¹äº‹ä»¶çš„åˆ†æ
   - å¼•å‘çš„æ€è€ƒ
   - ç›¸å…³èƒŒæ™¯çŸ¥è¯†
   - æé—®å¼•å¯¼è®¨è®º

**ç»†èŠ‚è¦æ±‚ï¼š**
- âœ… å¿…é¡»æåˆ°å…·ä½“æ—¶é—´ï¼ˆä»Šå¤©ã€æ˜¨å¤©ã€10æœˆXæ—¥ç­‰ï¼‰
- âœ… å¿…é¡»åŒ…å«å…·ä½“æ•°æ®ï¼ˆé‡‘é¢ã€æ•°é‡ã€çƒ­åº¦ç­‰ï¼‰
- âœ… å¿…é¡»è¯´æ˜æ¥æºï¼ˆå¾®åšã€Bç«™ã€çŸ¥ä¹ç­‰ï¼‰
- âœ… æè¿°è¦å…·ä½“ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
- âŒ ä¸è¦ç”¨"æœ€è¿‘"ã€"å‰æ®µæ—¶é—´"ç­‰æ¨¡ç³Šè¡¨è¿°
- âŒ ä¸è¦çœç•¥å…³é”®æ•°æ®

**æ ¼å¼ç¤ºä¾‹ï¼š**
```
ğŸ“° ã€æ–°é—»æ ‡é¢˜ã€‘
ã€æ—¶é—´ã€‘+ å…·ä½“äº‹ä»¶æè¿° + å…³é”®æ•°æ® + äº‹ä»¶ç»è¿‡ + ç»“æœã€‚
æ¥æºï¼šã€å¹³å°åç§°ã€‘ï¼Œçƒ­åº¦ï¼šã€å…·ä½“æ•°å€¼ã€‘

ğŸ’­ ä½ çš„è¯„è®º/è§‚ç‚¹/æé—®
åŸºäºå…·ä½“ç»†èŠ‚çš„åˆ†æã€æ€è€ƒæˆ–æé—®ã€‚
```

**åˆ›ä½œæ­¥éª¤ï¼š**
1. **è¯»å–ä¸Šä¸€æ¡æ¶ˆæ¯**ï¼šæå–çƒ­ç‚¹åˆ†ææ•°æ®
2. **é€‰æ‹©çƒ­ç‚¹**ï¼šæŒ‘é€‰ 3-4 ä¸ªæœ€çƒ­çš„è¯é¢˜ï¼ˆæ§åˆ¶æ€»å­—æ•°åœ¨1000å­—ä»¥å†…ï¼‰
3. **æå–ç»†èŠ‚**ï¼šä»æ•°æ®ä¸­æå–æ—¶é—´ã€æ•°æ®ã€æ¥æºç­‰ä¿¡æ¯
4. **åˆ›ä½œæ ‡é¢˜**ï¼š
   - ä¸¥æ ¼æ§åˆ¶åœ¨20å­—ä»¥å†…
   - æ ¼å¼ï¼šğŸ”¥ + æ—¥æœŸï¼ˆå¦‚10.23ï¼‰+ æ ¸å¿ƒè¯é¢˜ï¼ˆç®€çŸ­ï¼‰
   - ç¤ºä¾‹ï¼šğŸ”¥10.23çƒ­æœï¼å­¦ç”Ÿæ¢—+é‡‘åº¸ï¼ˆ18å­—ï¼‰
5. **åˆ›ä½œæ–‡æ¡ˆ**ï¼š
   - å¼€å¤´ï¼šç®€çŸ­å¸å¼•æ³¨æ„ï¼ˆ1-2å¥è¯ï¼‰+ ä»Šå¤©æ—¥æœŸï¼ˆ50å­—ä»¥å†…ï¼‰
   - ä¸»ä½“ï¼š3-4æ¡æ–°é—»ï¼Œæ¯æ¡åŒ…å«ğŸ“°æ–°é—»å†…å®¹ + ğŸ’­æ—¶è¯„ï¼ˆæ¯æ¡200-250å­—ï¼‰
   - ç»“å°¾ï¼šäº’åŠ¨å¼•å¯¼ï¼ˆ30å­—ä»¥å†…ï¼‰
   - æ€»è®¡ï¼šæ§åˆ¶åœ¨950å­—ä»¥å†…
6. **ä¿æŒçœŸå®**ï¼šä½¿ç”¨åŸå§‹æ ‡é¢˜å’ŒçœŸå®æ•°æ®ï¼Œä¸ç¼–é€ 

**è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»æ˜¯çº¯ JSONï¼Œä¸è¦ markdownï¼‰ï¼š**
{
  "title": "ğŸ”¥æ ‡é¢˜ï¼ˆä¸¥æ ¼æ§åˆ¶åœ¨20å­—ä»¥å†…ï¼ŒåŒ…å«emojiå’Œæ—¥æœŸï¼‰",
  "content": "æ­£æ–‡å†…å®¹ï¼ˆä¸¥æ ¼æ§åˆ¶åœ¨1000å­—ä»¥å†…ï¼ŒåŒ…å«3-4æ¡æ–°é—»å³å¯ï¼‰",
  "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"],
  "images": [],
  "cover_suggestion": "å°é¢å›¾å»ºè®®æè¿°",
  "source_hotspots": ["çƒ­ç‚¹1åŸå§‹æ ‡é¢˜", "çƒ­ç‚¹2åŸå§‹æ ‡é¢˜", "çƒ­ç‚¹3åŸå§‹æ ‡é¢˜"]
}

**å­—æ•°é™åˆ¶ï¼ˆé‡è¦ï¼‰ï¼š**
- æ ‡é¢˜ï¼šæœ€å¤š20ä¸ªå­—ï¼ˆåŒ…å«emojiå’Œæ ‡ç‚¹ç¬¦å·ï¼‰
- å†…å®¹ï¼šæœ€å¤š1000ä¸ªå­—ï¼ˆå»ºè®®800-950å­—ï¼‰
- å¦‚æœå†…å®¹å¤ªé•¿ï¼Œåªé€‰æ‹©3-4æ¡æœ€çƒ­çš„æ–°é—»

**æ³¨æ„**ï¼šimages å­—æ®µç•™ç©ºæ•°ç»„ []ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¡«å……é»˜è®¤å›¾ç‰‡ã€‚

**ç¤ºä¾‹ï¼ˆæ³¨æ„ï¼šç›´æ¥è¾“å‡º JSONï¼Œä¸è¦ markdown ä»£ç å—ï¼‰ï¼š**
å‡è®¾åˆ†ææ•°æ®ä¸­æœ‰ï¼š
- "æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡"ï¼ˆå¾®åšçƒ­æœï¼Œ360ä¸‡çƒ­åº¦ï¼Œ10æœˆ22æ—¥ï¼‰
- "å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·"ï¼ˆçŸ¥ä¹çƒ­æ¦œï¼Œ245ä¸‡çƒ­åº¦ï¼Œ10æœˆ23æ—¥ï¼‰

åˆ™ç›´æ¥è¾“å‡ºï¼š
{"title": "ğŸ”¥10.23çƒ­æœï¼å¥”é©°ç†èµ”+åç”»æµæ‹", "content": "å§å¦¹ä»¬ï¼10æœˆ23æ—¥çš„çƒ­æœçœŸçš„å¤ªç‚¸äº†ï¼ğŸ˜±\\n\\nğŸ“° æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡\\n10æœˆ22æ—¥ï¼Œä¸€ä½è½¦ä¸»åœ¨å¾®åšçˆ†æ–™ï¼Œè‡ªå·±èŠ±52ä¸‡å…ƒè´­ä¹°çš„å¥”é©°è½¿è½¦åœ¨é«˜é€Ÿä¸Šè¢«è¿½å°¾ï¼Œè½¦è¾†å‡ ä¹æŠ¥åºŸæ— æ³•ä¿®å¤ã€‚ç„¶è€Œä¿é™©å…¬å¸è¯„ä¼°åï¼Œåªæ„¿æ„èµ”ä»˜24ä¸‡å…ƒï¼Œç†ç”±æ˜¯æŒ‰ç…§è½¦è¾†æŠ˜æ—§åçš„å®é™…ä»·å€¼è®¡ç®—ã€‚è¯¥è¯é¢˜åœ¨å¾®åšè·å¾—360ä¸‡çƒ­åº¦ã€‚\\n\\nğŸ’­ è¿™ä¸ªç†èµ”æ–¹å¼çœŸçš„åˆç†å—ï¼ŸèŠ±52ä¸‡ä¹°çš„è½¦åªèµ”24ä¸‡ï¼Œç›¸å½“äºç›´æ¥æŸå¤±äº†ä¸€åŠï¼å¤§å®¶ä¹°è½¦é™©çš„æ—¶å€™ä¸€å®šè¦ä»”ç»†çœ‹æ¸…æ¥šæ¡æ¬¾ï¼Œç‰¹åˆ«æ˜¯å…³äºæŠ˜æ—§ç‡å’Œèµ”ä»˜æ ‡å‡†çš„éƒ¨åˆ†ï¼\\n\\nğŸ“° å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·\\n10æœˆ23æ—¥ï¼Œåœ¨æŸçŸ¥åæ‹å–è¡Œä¸¾åŠçš„ç§‹å­£æ‹å–ä¼šä¸Šï¼Œè‘—åç”»å®¶å¾æ‚²é¸¿çš„ä»£è¡¨ä½œã€Šå¥”é©¬å›¾ã€‹äº®ç›¸ï¼Œèµ·æ‹ä»·é«˜è¾¾4762ä¸‡å…ƒã€‚ç„¶è€Œä»¤äººæ„å¤–çš„æ˜¯ï¼Œæ‹å–ç°åœºç«Ÿç„¶æ— äººä¸¾ç‰Œå‡ºä»·ï¼Œæœ€ç»ˆæµæ‹ã€‚è¯¥æ¶ˆæ¯åœ¨çŸ¥ä¹çƒ­æ¦œè·å¾—245ä¸‡çƒ­åº¦ã€‚\\n\\nğŸ’­ è‰ºæœ¯å“å¸‚åœºçœŸçš„é‡å†·äº†å—ï¼Ÿè¿˜æ˜¯å¤§å®¶å¯¹è¿™ä¸ªä»·æ ¼æœ‰ç–‘è™‘ï¼Ÿè¿‘å‡ å¹´è‰ºæœ¯å“æŠ•èµ„ç¡®å®ä¸å¦‚å‰å‡ å¹´ç«çƒ­ï¼Œå¯èƒ½è·Ÿç»æµç¯å¢ƒå’Œå¸‚åœºä¿¡å¿ƒæœ‰å…³ã€‚\\n\\nä½ ä»¬æ€ä¹ˆçœ‹ï¼Ÿè¯„è®ºåŒºèŠèŠï¼ğŸ‘‡", "tags": ["#ä»Šæ—¥çƒ­ç‚¹", "#çƒ­æœ", "#å¿…çœ‹"], "images": [], "cover_suggestion": "çƒ­ç‚¹è¯é¢˜æ‹¼å›¾ï¼Œé…è‰²é²œè‰³", "source_hotspots": ["æŠ•ä¿52ä¸‡å¥”é©°è¢«è¿½å°¾å‡ ä¹æŠ¥åºŸï¼Œä¿å¸åªèµ”24ä¸‡", "å¾æ‚²é¸¿ã€Šå¥”é©¬å›¾ã€‹èµ·æ‹ä»·4762ä¸‡æš‚æ— äººå‡ºä»·"]}

**é‡è¦**ï¼š
- âœ… å¿…é¡»ä»ä¸Šä¸€æ¡æ¶ˆæ¯ä¸­è¯»å–åˆ†ææ•°æ®
- âœ… ä½¿ç”¨çœŸå®çš„çƒ­ç‚¹æ ‡é¢˜
- âœ… æ¯æ¡æ–°é—»åˆ†ä¸¤æ®µï¼šğŸ“° æ–°é—»å†…å®¹ï¼ˆå«ç»†èŠ‚ï¼‰+ ğŸ’­ æ—¶è¯„è§‚ç‚¹
- âœ… æ–°é—»å†…å®¹å¿…é¡»åŒ…å«ï¼šæ—¶é—´ã€æ•°æ®ã€æ¥æºã€çƒ­åº¦
- âœ… æè¿°è¦å…·ä½“è¯¦ç»†ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
- âœ… æ—¶è¯„è¦æœ‰è§‚ç‚¹ã€åˆ†ææˆ–æé—®
- âœ… åœ¨æ ‡é¢˜ä¸­åŒ…å«æ—¥æœŸï¼ˆå¦‚ï¼š10.23ã€ä»Šæ—¥ç­‰ï¼‰
- âœ… åœ¨ source_hotspots ä¸­åˆ—å‡ºä½¿ç”¨çš„çƒ­ç‚¹
- âœ… å¿…é¡»åŒ…å« images å­—æ®µï¼ˆç©ºæ•°ç»„ï¼‰
- âœ… ç›´æ¥è¾“å‡º JSON å¯¹è±¡ï¼Œç¬¬ä¸€ä¸ªå­—ç¬¦å¿…é¡»æ˜¯ {
- âŒ ä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„çƒ­ç‚¹
- âŒ ä¸è¦ä½¿ç”¨"æœ€è¿‘"ã€"å‰æ®µæ—¶é—´"ç­‰æ¨¡ç³Šè¡¨è¿°
- âŒ ä¸è¦çœç•¥å…·ä½“æ•°æ®å’Œæ—¶é—´
- âŒ ä¸è¦æŠŠæ–°é—»å†…å®¹å’Œè¯„è®ºæ··åœ¨ä¸€èµ·
- âŒ ç»å¯¹ä¸è¦ä½¿ç”¨ markdown ä»£ç å—ï¼ˆ```json æˆ– ```ï¼‰
- âŒ ä¸è¦åœ¨ JSON å‰åæ·»åŠ ä»»ä½•è¯´æ˜æ–‡å­—
"""

# åˆ›å»ºæ–‡æœ¬è½¬æ¢ Executorï¼Œç¡®ä¿ workflow ä¸­ä¼ é€’çš„æ¶ˆæ¯æ˜¯çº¯æ–‡æœ¬
class TextOnlyConversation(Executor):
    """ç¡®ä¿å¯¹è¯ä¸­åªåŒ…å«çº¯æ–‡æœ¬ï¼Œé¿å… TextContent åºåˆ—åŒ–é—®é¢˜"""
    
    def __init__(self, executor_id: str):
        super().__init__(id=executor_id)
    
    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç† markdown ä»£ç å—ï¼Œæå–çº¯ JSON"""
        import re
        
        # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
        # åŒ¹é… ```json ... ``` æˆ– ``` ... ```
        cleaned = re.sub(r'```(?:json)?\s*\n?(.*?)\n?```', r'\1', text, flags=re.DOTALL)
        
        # ç§»é™¤å‰åç©ºç™½
        cleaned = cleaned.strip()
        
        return cleaned
    
    @handler
    async def convert(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage]]) -> None:
        """
        å°† ChatMessage è½¬æ¢ä¸º DevUI å¯ä»¥æ­£ç¡®åºåˆ—åŒ–çš„æ ¼å¼
        
        å…³é”®ï¼šä¸å†åˆ›å»ºæ–°çš„ ChatMessageï¼Œè€Œæ˜¯ç›´æ¥å‘é€æå–çš„æ–‡æœ¬å­—ç¬¦ä¸²ã€‚
        DevUI ä¼šè‡ªåŠ¨å°†å­—ç¬¦ä¸²åŒ…è£…ä¸ºæ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼ã€‚
        """
        import logging
        logger = logging.getLogger(__name__)
        
        logger.info(f"[{self.id}] æ”¶åˆ° {len(messages)} æ¡æ¶ˆæ¯ï¼Œå¼€å§‹è½¬æ¢...")
        
        # æå–æ‰€æœ‰æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
        all_text_parts = []
        
        for i, msg in enumerate(messages):
            # ä½¿ç”¨ ChatMessage.text å±æ€§ï¼Œå®ƒä¼šè‡ªåŠ¨æå–æ‰€æœ‰æ–‡æœ¬å†…å®¹
            text = msg.text if hasattr(msg, 'text') else ""
            
            if text:
                # æ¸…ç† markdown ä»£ç å—
                cleaned_text = self._clean_markdown(text)
                all_text_parts.append(cleaned_text)
                logger.debug(f"[{self.id}] æ¶ˆæ¯ {i}: æå–æ–‡æœ¬ï¼Œé•¿åº¦={len(cleaned_text)}")
            else:
                logger.warning(f"[{self.id}] æ¶ˆæ¯ {i}: æ— æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡")
        
        # åˆå¹¶æ‰€æœ‰æ–‡æœ¬ï¼ˆå¦‚æœæœ‰å¤šæ¡æ¶ˆæ¯ï¼‰
        if all_text_parts:
            combined_text = "\n\n".join(all_text_parts)
            logger.info(f"[{self.id}] è½¬æ¢å®Œæˆï¼Œåˆå¹¶æ–‡æœ¬é•¿åº¦={len(combined_text)}")
            
            # ç›´æ¥å‘é€çº¯æ–‡æœ¬å­—ç¬¦ä¸²ï¼Œè®©æ¡†æ¶è‡ªåŠ¨åŒ…è£…
            # è¿™æ · DevUI å°±èƒ½æ­£ç¡®å¤„ç†å®ƒ
            await ctx.send_message(combined_text)
        else:
            logger.warning(f"[{self.id}] æ²¡æœ‰æå–åˆ°ä»»ä½•æ–‡æœ¬å†…å®¹")
            # å‘é€ç©ºæ¶ˆæ¯ä»¥ç»´æŒ workflow æµç¨‹
            await ctx.send_message("")



# åˆ›å»º Agents å’Œ Executors
logger.info("æ­£åœ¨åˆ›å»º Agents å’Œ Executors...")

# âœ… ä½¿ç”¨è‡ªå®šä¹‰ Executor æ›¿ä»£ç›´æ¥ç»‘å®š MCP å·¥å…·çš„ Agent
mcp_url = os.getenv("DAILY_HOT_MCP_URL", "http://localhost:8000/mcp")
hotspot_executor = MCPHotspotExecutor(
    executor_id="mcp_hotspot_executor",
    mcp_url=mcp_url,
    client=client
)
logger.info(f"âœ… Hotspot Executor åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå¸¦æœ‰ think-tool çš„ Analysis Executorï¼ˆä½¿ç”¨ stdio MCPï¼‰
class AnalysisExecutor(Executor):
    """å¸¦æœ‰ think-tool çš„åˆ†æ executor"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… AnalysisExecutor åˆ›å»º: {executor_id}")
    
    @handler
    async def analyze_with_thinking(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """ä½¿ç”¨ think-tool è¿›è¡Œæ·±åº¦åˆ†æ"""
        logger.info(f"[{self.id}] å¼€å§‹åˆ†æçƒ­ç‚¹æ•°æ®")
        
        try:
            # âœ… ä½¿ç”¨ MCPStdioTool è¿æ¥æœ¬åœ° think-tool
            from agent_framework import MCPStdioTool
            
            async with MCPStdioTool(
                name="think-tool",
                command="npx",
                args=["-y", "@cgize/mcp-think-tool"],
                load_tools=True
            ) as think_tool:
                logger.info(f"[{self.id}] think-tool å·²è¿æ¥")
                
                # åˆ›å»ºå¸¦æœ‰ think-tool çš„åˆ†æ agent
                analysis_agent = self.client.create_agent(
                    name="analysis_agent_with_thinking",
                    instructions=ANALYSIS_INSTRUCTIONS,
                    tools=[think_tool]
                )
                
                # æ‰§è¡Œåˆ†æ
                result = await analysis_agent.run(messages)
                result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result_text)}")
                
                # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
                from agent_framework import Role, TextContent
                response_msg = ChatMessage(
                    role=Role.ASSISTANT,
                    contents=[TextContent(text=result_text)]
                )
                await ctx.send_message([response_msg])
                
                # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
                summary = f"ğŸ§  **æ­¥éª¤ 2: æ·±åº¦åˆ†æå®Œæˆ**\n\nä½¿ç”¨ think-tool å®Œæˆåˆ†æ\nç»“æœé•¿åº¦: {len(result_text)} å­—ç¬¦\n\né¢„è§ˆï¼š\n```\n{result_text[:500]}\n```\n\n---\n"
                await ctx.yield_output(summary)
                
        except Exception as e:
            logger.error(f"[{self.id}] åˆ†æå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_result = '{"error": "åˆ†æå¤±è´¥: ' + str(e) + '"}'
            from agent_framework import Role, TextContent
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

analysis_executor = AnalysisExecutor(
    executor_id="analysis_executor_with_thinking",
    client=client
)
logger.info(f"âœ… Analysis Executor (with think-tool) åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ Executorï¼ˆè¾“å‡ºä¸­é—´ç»“æœï¼‰
class XiaohongshuContentExecutor(Executor):
    """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆçš„ executor"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… XiaohongshuContentExecutor åˆ›å»º: {executor_id}")
    
    @handler
    async def create_content(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ"""
        logger.info(f"[{self.id}] å¼€å§‹ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ")
        
        try:
            # åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ agent
            xiaohongshu_agent = self.client.create_agent(
                name="xiaohongshu_creator",
                instructions=XIAOHONGSHU_INSTRUCTIONS
            )
            
            # æ‰§è¡Œç”Ÿæˆ
            result = await xiaohongshu_agent.run(messages)
            result_text = result.text if hasattr(result, 'text') else str(result)
            
            logger.info(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(result_text)}")
            
            # âœ… è‡ªåŠ¨æ·»åŠ é»˜è®¤å›¾ç‰‡ï¼ˆå¦‚æœæ–‡æ¡ˆä¸­æ²¡æœ‰å›¾ç‰‡ï¼‰
            import json
            try:
                content_json = json.loads(result_text)
                images = content_json.get("images", [])
                
                # å¦‚æœæ²¡æœ‰å›¾ç‰‡ï¼Œä½¿ç”¨é»˜è®¤å›¾ç‰‡
                if not images:
                    default_images_str = os.getenv("XHS_DEFAULT_IMAGES", "")
                    if default_images_str:
                        images = [img.strip() for img in default_images_str.split(",") if img.strip()]
                        content_json["images"] = images
                        result_text = json.dumps(content_json, ensure_ascii=False)
                        logger.info(f"[{self.id}] å·²æ·»åŠ é»˜è®¤å›¾ç‰‡: {images}")
                    else:
                        logger.warning(f"[{self.id}] æœªé…ç½®é»˜è®¤å›¾ç‰‡ (XHS_DEFAULT_IMAGES)")
            except json.JSONDecodeError:
                logger.warning(f"[{self.id}] æ–‡æ¡ˆä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
            
            # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
            from agent_framework import Role, TextContent
            response_msg = ChatMessage(
                role=Role.ASSISTANT,
                contents=[TextContent(text=result_text)]
            )
            await ctx.send_message([response_msg])
            
            # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
            summary = f"âœï¸ **æ­¥éª¤ 3: å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ**\n\næ–‡æ¡ˆé•¿åº¦: {len(result_text)} å­—ç¬¦\n\nå®Œæ•´å†…å®¹ï¼š\n```json\n{result_text}\n```\n\n---\n"
            await ctx.yield_output(summary)
            
        except Exception as e:
            logger.error(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_result = '{"error": "æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: ' + str(e) + '"}'
            from agent_framework import Role, TextContent
            error_msg = ChatMessage(role=Role.ASSISTANT, contents=[TextContent(text=error_result)])
            await ctx.send_message([error_msg])

# âœ… åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ Executorï¼ˆè¾“å‡ºä¸­é—´ç»“æœï¼‰
class XiaohongshuContentExecutor(Executor):
    """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆçš„ executor"""
    
    def __init__(self, executor_id: str, client):
        super().__init__(id=executor_id)
        self.client = client
        logger.info(f"âœ… XiaohongshuContentExecutor åˆ›å»º: {executor_id}")
    
    @handler
    async def create_content(self, messages: list[ChatMessage], ctx: WorkflowContext[list[ChatMessage], str]) -> None:
        """ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ"""
        logger.info(f"[{self.id}] å¼€å§‹ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ")
        
        try:
            # åˆ›å»ºå°çº¢ä¹¦å†…å®¹ç”Ÿæˆ agent
            xiaohongshu_agent = self.client.create_agent(
                name="xiaohongshu_creator",
                instructions=XIAOHONGSHU_INSTRUCTIONS
            )
            
            # æ‰§è¡Œç”Ÿæˆ
            result = await xiaohongshu_agent.run(messages)
            result_text = result.text if hasattr(result, 'text') else str(result)
            
            logger.info(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(result_text)}")
            
            # âœ… è‡ªåŠ¨æ·»åŠ é»˜è®¤å›¾ç‰‡
            import json
            try:
                content_json = json.loads(result_text)
                images = content_json.get("images", [])
                
                if not images:
                    default_images_str = os.getenv("XHS_DEFAULT_IMAGES", "")
                    if default_images_str:
                        images = [img.strip() for img in default_images_str.split(",") if img.strip()]
                        content_json["images"] = images
                        result_text = json.dumps(content_json, ensure_ascii=False)
                        logger.info(f"[{self.id}] å·²æ·»åŠ é»˜è®¤å›¾ç‰‡: {images}")
                
                # åˆ›å»ºå†…å®¹é¢„è§ˆ
                title = content_json.get("title", "")
                content = content_json.get("content", "")
                tags = content_json.get("tags", [])
                
            except json.JSONDecodeError:
                logger.warning(f"[{self.id}] æ–‡æ¡ˆä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œè·³è¿‡å›¾ç‰‡å¤„ç†")
            
            # âœ… å‘é€å®Œæ•´æ•°æ®åˆ°ä¸‹ä¸€ä¸ª executor
            from agent_framework import Role, TextContent
            response_msg = ChatMessage(
                role=Role.ASSISTANT,
                contents=[TextContent(text=result_text)]
            )
            await ctx.send_message([response_msg])
            
            # âœ… åŒæ—¶è¾“å‡ºä¸­é—´ç»“æœç»™ç”¨æˆ·
            summary = f"âœï¸ **æ­¥éª¤ 3: å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆå®Œæˆ**\n\næ–‡æ¡ˆé•¿åº¦: {len(result_text)} å­—ç¬¦\n\nå®Œæ•´å†…å®¹ï¼š\n```json\n{result_text}\n```\n\n---\n"
            await ctx.yield_output(summary)
            
        except Exception as e:
            logger.error(f"[{self.id}] æ–‡æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

xiaohongshu_executor = XiaohongshuContentExecutor(
    executor_id="xiaohongshu_content_executor",
    client=client
)
logger.info(f"âœ… Xiaohongshu Content Executor åˆ›å»ºå®Œæˆ")

# âœ… åˆ›å»ºå°çº¢ä¹¦å‘å¸ƒ Executorï¼ˆä½¿ç”¨ xiaohongshu-mcpï¼‰
class XiaohongshuPublisher(Executor):
    """ä½¿ç”¨ xiaohongshu-mcp å‘å¸ƒåˆ°å°çº¢ä¹¦"""
    
    def __init__(self, executor_id: str, client, xhs_mcp_url: str = "http://localhost:18060/mcp"):
        super().__init__(id=executor_id)
        self.client = client
        self.xhs_mcp_url = xhs_mcp_url
        logger.info(f"âœ… XiaohongshuPublisher åˆ›å»º: {executor_id}, MCP URL: {xhs_mcp_url}")
    
    @handler
    async def publish_to_xhs(self, messages: list[ChatMessage], ctx: WorkflowContext[Never, str]) -> None:
        """å‘å¸ƒå†…å®¹åˆ°å°çº¢ä¹¦ï¼ˆä½¿ç”¨ xiaohongshu-mcpï¼‰"""
        logger.info(f"[{self.id}] ========================================")
        logger.info(f"[{self.id}] ğŸš€ å‘å¸ƒ Executor è¢«è§¦å‘ï¼")
        logger.info(f"[{self.id}] æ”¶åˆ° {len(messages)} æ¡æ¶ˆæ¯")
        logger.info(f"[{self.id}] ========================================")
        
        try:
            # æå–å°çº¢ä¹¦æ–‡æ¡ˆ
            content_text = ""
            for msg in messages:
                if hasattr(msg, 'text') and msg.text:
                    content_text = msg.text
                    break
            
            logger.info(f"[{self.id}] æå–åˆ°æ–‡æ¡ˆï¼Œé•¿åº¦: {len(content_text)}")
            
            import json
            
            # è§£ææ–‡æ¡ˆ JSON
            try:
                content_json = json.loads(content_text)
                title = content_json.get("title", "")
                content = content_json.get("content", "")
                tags = content_json.get("tags", [])
                images = content_json.get("images", [])  # è·å–å›¾ç‰‡åˆ—è¡¨
            except json.JSONDecodeError:
                logger.error(f"[{self.id}] æ–‡æ¡ˆä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼")
                error_result = '{"status": "failed", "message": "æ–‡æ¡ˆæ ¼å¼é”™è¯¯ï¼Œä¸æ˜¯æœ‰æ•ˆçš„ JSON"}'
                await ctx.yield_output(error_result)
                return
            
            # æ£€æŸ¥æ ‡é¢˜å’Œå†…å®¹é•¿åº¦ï¼ˆå°çº¢ä¹¦é™åˆ¶ï¼‰
            if len(title) > 20:
                logger.warning(f"[{self.id}] æ ‡é¢˜è¶…è¿‡ 20 å­—ï¼Œå°†è¢«æˆªæ–­")
                title = title[:20]
            
            if len(content) > 1000:
                logger.warning(f"[{self.id}] å†…å®¹è¶…è¿‡ 1000 å­—ï¼Œå°†è¢«æˆªæ–­")
                content = content[:1000]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å›¾ç‰‡
            if not images:
                # ä»ç¯å¢ƒå˜é‡è·å–é»˜è®¤å›¾ç‰‡è·¯å¾„
                default_images_str = os.getenv("XHS_DEFAULT_IMAGES", "")
                if default_images_str:
                    # æ”¯æŒå¤šä¸ªå›¾ç‰‡ï¼Œç”¨é€—å·åˆ†éš”
                    images = [img.strip() for img in default_images_str.split(",") if img.strip()]
                    logger.info(f"[{self.id}] ä½¿ç”¨é»˜è®¤å›¾ç‰‡: {images}")
                else:
                    logger.warning(f"[{self.id}] æœªæä¾›å›¾ç‰‡ä¸”æ— é»˜è®¤å›¾ç‰‡é…ç½®")
                    result_text = json.dumps({
                        "status": "skipped",
                        "message": "å°çº¢ä¹¦å‘å¸ƒéœ€è¦å›¾ç‰‡ã€‚è¯·åœ¨ .env ä¸­é…ç½® XHS_DEFAULT_IMAGES æˆ–åœ¨æ–‡æ¡ˆä¸­æä¾›å›¾ç‰‡è·¯å¾„ã€‚",
                        "title": title,
                        "content": content,
                        "tags": tags
                    }, ensure_ascii=False, indent=2)
                    
                    final_output = f"âš ï¸ **å‘å¸ƒè·³è¿‡**\n\næ ‡é¢˜: {title}\næ ‡ç­¾: {', '.join(tags)}\n\nåŸå› ï¼šå°çº¢ä¹¦å‘å¸ƒéœ€è¦å›¾ç‰‡\n\nå®Œæ•´å†…å®¹ï¼š\n{content_text}\n\n---\nğŸ’¡ æç¤ºï¼šåœ¨ .env ä¸­é…ç½® XHS_DEFAULT_IMAGES ç¯å¢ƒå˜é‡"
                    await ctx.yield_output(final_output)
                    return
            
            # âœ… ä½¿ç”¨ xiaohongshu-mcp å‘å¸ƒ
            from agent_framework import MCPStreamableHTTPTool
            
            logger.info(f"[{self.id}] è¿æ¥åˆ° xiaohongshu-mcp: {self.xhs_mcp_url}")
            
            # çœŸå®å‘å¸ƒ
            async with MCPStreamableHTTPTool(
                name="xiaohongshu-mcp",
                url=self.xhs_mcp_url,
                load_tools=True,
                load_prompts=False,  # âœ… é¿å… "Method not found" é”™è¯¯
                timeout=300  # âœ… 5åˆ†é’Ÿè¶…æ—¶ï¼Œå‘å¸ƒæ“ä½œå¯èƒ½è€—æ—¶è¾ƒé•¿
            ) as xhs_tool:
                logger.info(f"[{self.id}] xiaohongshu-mcp å·²è¿æ¥")
                
                # å°†æ ‡ç­¾æ·»åŠ åˆ°å†…å®¹æœ«å°¾
                content_with_tags = content
                if tags:
                    tags_str = " ".join([f"#{tag}" for tag in tags])
                    content_with_tags = f"{content}\n\n{tags_str}"
                
                # âœ… æ–¹æ¡ˆï¼šç›´æ¥è°ƒç”¨å·¥å…·ï¼ˆæ¨èï¼Œé¿å…å¤§æ¨¡å‹è¯¯è§£ï¼‰
                logger.info(f"[{self.id}] ç›´æ¥è°ƒç”¨ publish_content å·¥å…·...")
                logger.info(f"[{self.id}]   æ ‡é¢˜: {title}")
                logger.info(f"[{self.id}]   å†…å®¹é•¿åº¦: {len(content_with_tags)}")
                logger.info(f"[{self.id}]   å›¾ç‰‡: {images}")
                logger.info(f"[{self.id}]   æ ‡ç­¾: {tags}")
                
                try:
                    # ç›´æ¥è°ƒç”¨ publish_content å·¥å…·
                    # æ­£ç¡®çš„è°ƒç”¨æ–¹å¼ï¼šå·¥å…·åä½œä¸ºç¬¬ä¸€ä¸ªå‚æ•°ï¼Œå…¶ä»–å‚æ•°ä½œä¸ºå…³é”®å­—å‚æ•°
                    result = await xhs_tool.call_tool(
                        "publish_content",
                        title=title,
                        content=content_with_tags,
                        images=images,
                        tags=tags or []
                    )
                    
                    result_text = str(result)
                    logger.info(f"[{self.id}] å·¥å…·è°ƒç”¨æˆåŠŸ")
                    
                except Exception as tool_error:
                    logger.error(f"[{self.id}] ç›´æ¥è°ƒç”¨å·¥å…·å¤±è´¥: {tool_error}")
                    logger.info(f"[{self.id}] å°è¯•ä½¿ç”¨ Agent æ–¹å¼...")
                    
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨ Agent
                    publisher_agent = self.client.create_agent(
                        name="xhs_publisher",
                        instructions="""ä½ æ˜¯å°çº¢ä¹¦å‘å¸ƒåŠ©æ‰‹ã€‚

**å¯ç”¨å·¥å…·**: publish_content

**å·¥å…·å‚æ•°è¯´æ˜**:
- title (string, required): å†…å®¹æ ‡é¢˜ï¼ˆæœ€å¤š20ä¸ªå­—ï¼‰
- content (string, required): æ­£æ–‡å†…å®¹ï¼ˆæœ€å¤š1000ä¸ªå­—ï¼‰
- images (array of strings, required): å›¾ç‰‡è·¯å¾„åˆ—è¡¨
  * æ”¯æŒæœ¬åœ°ç»å¯¹è·¯å¾„ï¼ˆæ¨èï¼‰: å¦‚ "D:\\Pictures\\image.jpg"
  * æ”¯æŒ HTTP/HTTPS é“¾æ¥: å¦‚ "https://example.com/image.jpg"
  * è‡³å°‘éœ€è¦1å¼ å›¾ç‰‡
- tags (array of strings, optional): è¯é¢˜æ ‡ç­¾åˆ—è¡¨

**é‡è¦**: images å‚æ•°å¯ä»¥ç›´æ¥ä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œä¸éœ€è¦ä¸Šä¼ åˆ°ç½‘ç»œã€‚

**ä»»åŠ¡**: ä½¿ç”¨æä¾›çš„æ ‡é¢˜ã€å†…å®¹å’Œå›¾ç‰‡è°ƒç”¨ publish_content å·¥å…·å‘å¸ƒåˆ°å°çº¢ä¹¦ã€‚

**ç¤ºä¾‹**:
{
  "title": "æ˜¥å¤©çš„èŠ±æœµ",
  "content": "ä»Šå¤©æ‹åˆ°äº†ç¾ä¸½çš„æ¨±èŠ±",
  "images": ["D:\\Pictures\\spring.jpg"],
  "tags": ["æ˜¥å¤©", "æ¨±èŠ±"]
}
""",
                        tools=[xhs_tool]
                    )
                    
                    publish_request = f"""è¯·å‘å¸ƒå°çº¢ä¹¦ç¬”è®°ï¼š

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content_with_tags}
å›¾ç‰‡ï¼š{json.dumps(images, ensure_ascii=False)}
æ ‡ç­¾ï¼š{json.dumps(tags or [], ensure_ascii=False)}

ä½¿ç”¨ publish_content å·¥å…·è¿›è¡Œå‘å¸ƒã€‚
"""
                    
                    result = await publisher_agent.run(publish_request)
                    result_text = result.text if hasattr(result, 'text') else str(result)
                
                logger.info(f"[{self.id}] å‘å¸ƒå®Œæˆ: {result_text[:200]}")
                
                # è¾“å‡ºæœ€ç»ˆç»“æœ
                final_output = f"""ğŸš€ **å‘å¸ƒå®Œæˆ**

æ ‡é¢˜: {title}
æ ‡ç­¾: {', '.join(tags)}
å›¾ç‰‡æ•°é‡: {len(images)}

å‘å¸ƒç»“æœï¼š
{result_text}

---
âœ… Workflow æ‰§è¡Œå®Œæˆï¼
"""
                await ctx.yield_output(final_output)
                
        except Exception as e:
            logger.error(f"[{self.id}] å‘å¸ƒå¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            # è¿”å›é”™è¯¯ä¿¡æ¯
            error_result = f'{{"status": "failed", "message": "å‘å¸ƒå¤±è´¥: {str(e)}"}}'
            await ctx.yield_output(error_result)

# ä»ç¯å¢ƒå˜é‡è·å– xiaohongshu-mcp URLï¼ˆé»˜è®¤ localhost:18060ï¼‰
xhs_mcp_url = os.getenv("XIAOHONGSHU_MCP_URL", "http://localhost:18060/mcp")

xhs_publisher = XiaohongshuPublisher(
    executor_id="xhs_publisher",
    client=client,
    xhs_mcp_url=xhs_mcp_url
)
logger.info(f"âœ… Xiaohongshu Publisher åˆ›å»ºå®Œæˆ")

# æ„å»º workflowï¼ˆDevUI ä¼šæŸ¥æ‰¾åä¸º 'workflow' çš„å˜é‡ï¼‰
# âœ… æ–°çš„ workflow æ¶æ„ï¼ˆæ‰€æœ‰æ­¥éª¤éƒ½è¾“å‡ºä¸­é—´ç»“æœï¼‰ï¼š
# 1. Hotspot Executor - ä½¿ç”¨ daily-hot-mcp è·å–çƒ­ç‚¹
# 2. Analysis Executor - ä½¿ç”¨ think-tool æ·±åº¦åˆ†æ
# 3. Xiaohongshu Content Executor - ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
# 4. Xiaohongshu Publisher - å‘å¸ƒåˆ°å°çº¢ä¹¦
workflow = (
    SequentialBuilder()
    .participants([
        hotspot_executor,      # âœ… è·å–çƒ­ç‚¹ï¼ˆdaily-hot-mcpï¼‰
        analysis_executor,     # âœ… æ·±åº¦åˆ†æï¼ˆthink-toolï¼‰
        xiaohongshu_executor,  # âœ… ç”Ÿæˆå°çº¢ä¹¦æ–‡æ¡ˆ
        xhs_publisher          # âœ… å‘å¸ƒåˆ°å°çº¢ä¹¦
    ])
    .build()
)

# æ·»åŠ å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
workflow.name = "Xiaohongshu Hotspot Workflow"
workflow.description = "çƒ­ç‚¹è¿½è¸ª â†’ æ·±åº¦åˆ†æ â†’ å°çº¢ä¹¦æ–‡æ¡ˆç”Ÿæˆ â†’ è‡ªåŠ¨å‘å¸ƒ"
